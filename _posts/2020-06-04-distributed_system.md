---
layout: post
title: "一个研发工程师在短视频领域做了什么（二）高并发系统"
---
我过去一段时间的工作经历是开发支撑一款千万级日活的用户产品（to C）的后台，和企业级（to B）产品不同，用户产品的后台没有过于复杂的业务逻辑，但却需要应对大量用户同时访问可能带来的高并发请求对系统的冲击。面对高并发的冲击，业务系统如何保证其业务逻辑正确性的基础上，同时保证服务的响应速度，是衡量系统可用性的关键。这里通常有两个指标来衡量：吞吐量和延迟。吞吐量指的是单位时间能处理多少请求，高并发请求通常也就意味着高吞吐量。延迟指的是一个请求需要耗费多长时间得到响应。当有大量的上游用户请求同时访问系统（吞吐量增加），请求量增加到瓶颈后，由于计算资源的限制，请求就会相互抢占资源，导致指标的下降。也就是说高并发系统需要保证系统有高吞吐量和低延时。

# 如何优化

## 优化实现
这是在进行代码开发时所可以进行的优化，这些优化都是最核心最底层的涉及到硬件资源的利用效率，直观上就是项目投资的每一分钱发挥多大的价值：

* **算法优化**：这是工程师的基本能力，我们在面试时之所以考察算法和数据结构的能力，就是要在开发时尽可能减少时间复杂度和空间复杂度，以节省计算和存储资源。
* **语言优化**：不同语言有不同的特点，有的语言为了灵活性放弃了性能如python，有的语言性能强大却难以驾驭如c，针对不同的系统诉求选择合适的语言进行开发时十分重要的。

## 扩展资源
除了提高资源的利用率之外，更直接有效的解决这个问题方式就是增加投入，扩展资源。这里的资源，可能包含CPU、内存、存储等。然而，资源的扩展不是简单的叠加，是有诸多限制的。对于一台计算机上，CPU、内存、IO等资源在操作系统的组织下协调运行，但受体系结构限制，扩展资源是有极限的。此时，要继续扩展资源需要通过网络连接多个计算机，组成分布式系统，这样可以使用的资源就可以扩展多个计算机。但分布式系统引入网络传输，资源调度的方式与仅仅是操作系统调度有了很大不同，不仅是分配到哪个CPU或者哪个核，在这之上还要知道调度到哪个机器节点，这个协调的工作就需要额外的算法和服务来完成。同时系统组件增多，复杂程度提高，容错性能也是其能否达成提高高并发性能的重要因素。

* **有状态扩展**: 内存、磁盘这些存储资源通常会与请求相关的数据挂钩，也就是说系统中不同的节点只保留着部分数据，对应的请求也只能访问这些数据。此时，扩展节点资源必然会影响数据的分布，这就涉及到了不同的数据分布、迁移的策略。通常我们使用sharding的方式去设计这样的结构，保证不同数据合理的分配到对应的节点上。

* **无状态扩展**: 当扩展的资源不需要存储每个请求的状态时，那么所有的资源都是对等的，使用哪些来处理请求是没有区别的。此时我们通常使用replication的方式，直接复制不同节点的配置扩展到新节点上。

在不同场景下，sharding或是replication的方式应用不是互斥的，大部分场景会融合不仅保证扩展性还要保证容错性。

## 资源的调度
如之前所说，系统资源单机扩展成网络，调度资源也不仅仅只依靠操作系统完成。这里的调度，不仅仅指流量的调度，也包含资源如何初始化等其他内容。首先就涉及到资源的naming问题，最简单的方式就是使用IP地址和端口号进行定位从而知道有哪些资源可供我们调度。之后就需要管理这些节点资源的增加、删除、修改。完成配置后，分配对应的流量到相应的资源上。而在系统中，承担调度的角色，通常可以分为两种：
* **中心化**: 系统中有专门的节点进行调度。

* **非中心化**：系统中每个节点都能可以进行调度。

这两种方式各有利弊，中心化的方式更方便管理但可能出现单点失败，而非中心化的方式保证了稳定性但需要保证数据一致的overhead。

# 容错性
实际上容错性是分布式系统引入复杂性之后的overhead，尤其是在引入了更多的网络传输之后，各个组件fail的机会会增加。此时，容错性主要考量的是节点fail back和fail over：fail back指的是节点失败之后能够自动恢复；fail over指的是节点失败之后有相应的备援能够接受其工作。提高容错性就是围绕着两点来展开。

## 监测fail
通常我们说的是client-server的架构模式，那么我们怎么知道server故障了呢？最根本的，server内部有很多指标可以说明潜在的故障的发生，client也可以则大多时候可以通过timeout和其他明确的错误来感知。这样的检测方式会出现false positive，使得正常的节点被摘除，需要一段时间的累计

## 解决fail
解决fail问题的核心就是冗余，可以是空间和时间两个维度。这是很直观的方法，时间冗余指的是如果短时间失败可以重试，给系统有fail over的机会；空间冗余就是资源在不同的物理空间备份，给系统fail back的条件。当然这样的冗余也不是无限的，容错所带来的可用性是和响应时间相关的，过多的冗余会给系统产生overhead，极有可能使latency大幅延长。例如过多的重试会加剧系统资源的占用导致流量放大，服务器雪崩。而空间的冗余会增加保证数据一致性的开销。所以在实际场景中，解决容灾问题是在各种复杂因素综合评定下的tradeoff，并没有万能的策略解决所有的问题。

# 实践
## Golang
我们大量的线上系统都是用python构建的，因为业务需求的开发成本低。但因为python在性能上是有天生缺陷的，尤其事针对GIL需要在多线程上做大量优化。为了提高资源的利用率，我们分批次的将系统用golang重构，相应的服务都有50%以上的CPU和内存效率提升。

## load balance
一个web应用，背后是无数个微服务节点。 从最外层DNS，再到Nginx，再到服务发现组件consul，和各种数据库的proxy等，各个层次都需要不同的组件实现对应的load balance策略及其它的流量分配策略。例如，redis集群使用temproxy+cluster的组件，既有非中心化也有中心化的流量转发；mysql使用mycat做流量sharding工具；微服务client也集成了round robin算法和ratelimiter流量控制组件。

## 冗余
我们的视频产品，每天晚上都会有流量高峰，并且各种各样的运营活动也会带来瞬时的流量爆炸。因此，为了保证在极端情况下的服务稳定性。无论是计算节点还是存储节点，我们通常会保证一般流量高峰的50%冗余。同时，数据存储通常也会采用master-slave方式进行数据备份。这样的备份也需要做到跨数据中心，以防止更大范围的服务宕机。

## 监控
虽然我们希望建设尽可能自动化程度搞得系统, 但是很多保障业务准确性的工作还是需要工程师的介入进行判断。基于Grafana和opentsdb的实时多维度监控系统，将从基础设施的硬件资源，到业务流量数据，及每个接口的流量和延迟的变化都纳入监控范围内。当数值达到一定的阈值，会触发一定的自动化的熔断或拒绝服务的机制，同时会发出相关的通知进行报警，提醒工程师介入。

## 容灾
这里我们主要讨论工程师如何介入，来最小化故障损失。我们使用etcd对核心服务的关键环节配置开关，一旦局部发生故障，我们可能通过服务降级和熔断的方式保住核心服务。即便是正常时期，为了保证这样的应急处理能够妥善解决问题，我们也会通过一些chaos engineering的方式模拟进行容灾演练。

# 总结
算法和数据结构的时间和空间复杂的估算都没有考虑系统资源的限制，而在实际的生产环境中，尤其是在高并发请求的压力下，时间和空间复杂度的优化需要纳入资源这一重要维度进行考量。高并发的应用，需要建立在操作系统之上分布式的资源调度能力，来保证系统应对流量增加时的高扩展性和稳定性，在生产环境中，多因素作用的场景增加了系统设计的困难。